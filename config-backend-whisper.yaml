# Faster-Whisper Backend Configuration
# Uses faster-whisper for ASR and SpeechBrain ECAPA-TDNN for speaker embeddings

# Device identification
device_name: ${DEVICE_NAME:-default}

# Audio settings
audio_device: null  # null = system default, or device name/index
sample_rate: 16000  # 16kHz required for Whisper

# VAD-aware chunking settings
vad_threshold: 0.85  # Higher = less sensitive, filters more noise
silence_duration: 0.5  # Seconds of silence to trigger chunk boundary
min_chunk_duration: 2.0  # Minimum chunk size for reliable processing
max_chunk_duration: 30.0  # Force chunk even without silence
min_audio_energy: 0.01  # Minimum RMS energy to process
min_speech_duration: 0.4  # Minimum seconds of speech required

# Whisper model settings
# Options: tiny.en, base.en, small.en, medium.en, large-v2, large-v3
whisper_model: "medium.en"
whisper_compute_type: "int8"  # int8, float16, float32

# Transcript filtering - words to always ignore (e.g., keyboard clicks transcribed as gibberish)
# If a transcript consists entirely of these words, it will be filtered out
ignore_words: []  # Example: ["acl", "ack", "hmm"]

# Speaker identification
speaker_similarity_threshold: 0.75  # Cosine similarity for speaker matching
speaker_inactivity_timeout: 1800.0  # Reset after 30 min silence (seconds)

# Queue settings
queue_dir: "./data/queue-whisper"
